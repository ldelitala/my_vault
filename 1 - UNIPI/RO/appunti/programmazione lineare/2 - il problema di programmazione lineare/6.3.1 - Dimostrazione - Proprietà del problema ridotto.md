*status*: #bozza 
*tags*: [[RO]] [[PROGRAMMAZIONE LINEARE]]

## Dimostrazione - Proprietà del problema ridotto

1. **Se il problema ridotto non ha soluzioni ammissibili, allora anche il problema originale non ne ha** 

   Supponiamo che il problema ridotto:  
   $$
   \text{max} \{ c'x'_{new} : A'x'_{new} \leq b \}
   $$  
   non abbia soluzioni ammissibili. Allora:
   $$
A'x'_{new} \nleq b \quad \forall x'_{new} \in \mathbb{R}^{n-1}
$$
Dalla [[6.1 - Dimostrazione - Riduzione di variabili in un problema di PL con linealità]] abbiamo però visto che:
$$
 A'x'_{new} = A'(x'+\beta x_{n}) = A'x' + A'\beta x_{n} = A'x' + a^n x_{n} = Ax
$$
Quindi vale:
   $$
A'x'_{new} \nleq b \quad \forall x'_{new} \in \mathbb{R}^{n-1}
\quad \leftrightarrow \quad 
Ax \nleq b \quad \forall x \in \mathbb{R}^n
$$

2. **Se il problema ridotto è superiormente illimitato, allora anche il problema originale è superiormente illimitato**  

   Supponiamo che il problema ridotto sia superiormente illimitato.  
   - Esiste una direzione $d' \in \mathbb{R}^{n-1}$ tale che $A'd' \leq 0$ e $c'd' > 0$, il che significa che possiamo aumentare arbitrariamente la funzione obiettivo.  
   - Consideriamo la direzione $d = [d', 0] \in \mathbb{R}^n$.  
     - Poiché $Ax = [A', a^n][d', 0] = A'd'$, abbiamo $Ad \leq 0$.  
     - Inoltre, $cd = c'd' + c_n \cdot 0 = c'd' > 0$.  
   - Pertanto, anche il problema originale è superiormente illimitato.

3. **Se il problema ridotto ha una soluzione ottima $x'_{new}$, allora:**  
#### Preambolo necessario

Siccome per definizione $A'\beta = a^n$, se costruiamo $d=[\beta,-1]$  questa è una direzione di linealità, infatti:
$$
Ad = A' \beta + a^n(-1) = 0
$$
e dal [[2.1 - Corollario - Linealità di P]] sappiamo che d è quindi vettore di linealità.

Se $x'_{new}$ è la nostra soluzione ottima del problema ridotto, sappiamo che possiamo costruire una soluzione ammissibile $x = [x'_{new},0]$ del problema originale. Inoltre, siccome $d$ è di linealità, sappiamo che $x + \alpha d$ è soluzione ammissibile del problema originale $\forall \alpha$.

Se calcoliamo il costo, abbiamo quindi:
$$
 c(x+\alpha d)= cx +\alpha cd
$$

##### Caso $cd =0$

$$
 c(x+\alpha d)= cx +\alpha cd = cx =c'x'_{new} + c_{n}0=c'x'_{new} \quad \forall\alpha
$$

In pratica $\alpha cd$ si annulla per l'ipotesi e così dimostriamo che tutte le soluzioni possibili al variare di $\alpha$ hanno lo stesso costo del problema ridotto e sono quindi tutte soluzioni ottime.

##### Caso $cd \neq 0$
$$
 c(x+\alpha d)= cx +\alpha cd = cx =c'x'_{new} + c_{n}0 + \alpha cd 
 = c'x'_{new} + \alpha c d \quad \forall \alpha
$$

Come possiamo notare, a seconda se $cd <0$ o $cd >0$ possiamo sempre trovare un $\alpha$ che renda il problema superiormente illimitato.

## Riferimenti utili

* [[6 - Teorema - Riduzione di variabili in un problema di PL con linealità]]
* [[6.1 - Dimostrazione - Riduzione di variabili in un problema di PL con linealità]]
* [[3 - Teorema - condizione di illimitatezza superiore al problema di PL]]
* [[2.1 - Corollario - Linealità di P]]